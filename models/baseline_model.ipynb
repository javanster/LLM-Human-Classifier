{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model - Naive Bayes\n",
    "\n",
    "This notebook contains:\n",
    "- Code for training a baseline model using Naive Bayes to classify texts as being either LLM-generated or human-written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size before removing rows identical to the training data: 73573\n",
      "Train and pretest data size: 158294\n",
      "Test data size: 40202\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_and_pretest_data = pd.read_csv('../data/detect_ai.csv')\n",
    "test_data = pd.read_csv('../data/daigt_v4.csv')\n",
    "\n",
    "print(f\"Test data size before removing rows identical to the training data: {len(test_data)}\")\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data.drop_duplicates(subset='text')\n",
    "test_data = test_data[~test_data['text'].isin(train_and_pretest_data['text'])]\n",
    "\n",
    "print(f\"Train and pretest data size: {len(train_and_pretest_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "# nltk.download('punkt') # Uncomment this line if you haven't downloaded the 'punkt' package\n",
    "\n",
    "def preprocess_data(data):\n",
    "    tokens = word_tokenize(data.lower())\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "train_pretest_tokenized_df = pd.DataFrame(columns=['tokens', 'label'])\n",
    "test_tokenized_df = pd.DataFrame(columns=['tokens', 'label'])\n",
    "\n",
    "for index, row in train_and_pretest_data.iterrows():\n",
    "    train_pretest_tokenized_df = pd.concat([train_pretest_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['generated']}, index=[0])], ignore_index=True)\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    test_tokenized_df = pd.concat([test_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['label']}, index=[0])], ignore_index=True)\n",
    "\n",
    "train_data, pretest_data = train_test_split(train_pretest_tokenized_df, stratify=train_pretest_tokenized_df.label, test_size=0.2)\n",
    "\n",
    "train_data.to_csv(\"../data/baseline_processed_train_data.csv\")\n",
    "pretest_data.to_csv(\"../data/baseline_processed_pretest_data.csv\")\n",
    "test_tokenized_df.to_csv(\"../data/baseline_processed_test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the training data: 126635\n",
      "Number of entries in the test data: 31659\n",
      "\n",
      "\n",
      "Proportion of the data:\n",
      "\n",
      "                     Data overall         Train data           Test data           \n",
      "Human written        0.2288               0.2288               0.2288              \n",
      "LLM generated        0.7712               0.7712               0.7712              \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../data/baseline_processed_train_data.csv\")\n",
    "pretest_data = pd.read_csv(\"../data/baseline_processed_pretest_data.csv\")\n",
    "test_data = pd.read_csv(\"../data/baseline_processed_test_data.csv\")\n",
    "\n",
    "print(f\"Number of entries in the training data: {train_data.shape[0]}\")\n",
    "print(f\"Number of entries in the test data: {pretest_data.shape[0]}\")\n",
    "\n",
    "data_label_0_proportion = train_and_pretest_data[train_and_pretest_data.generated == 0].shape[0] / train_and_pretest_data.shape[0]\n",
    "data_label_1_proportion = train_and_pretest_data[train_and_pretest_data.generated == 1].shape[0] / train_and_pretest_data.shape[0]\n",
    "\n",
    "train_data_label_0_propotion = train_data[train_data.label == 0].shape[0] / train_data.shape[0]\n",
    "train_data_label_1_propotion = train_data[train_data.label == 1].shape[0] / train_data.shape[0]\n",
    "\n",
    "pretest_data_label_0_propotion = pretest_data[pretest_data.label == 0].shape[0] / pretest_data.shape[0]\n",
    "pretest_data_label_1_propotion = pretest_data[pretest_data.label == 1].shape[0] / pretest_data.shape[0]\n",
    "\n",
    "print(\"\\n\\nProportion of the data:\")\n",
    "print(f\"\\n{'':<20s} {'Data overall':<20s} {'Train data':<20s} {'Test data':<20s}\")\n",
    "print(f\"{'Human written':<20s} {data_label_0_proportion:<20.4f} {train_data_label_0_propotion:<20.4f} {pretest_data_label_0_propotion:<20.4f}\")\n",
    "print(f\"{'LLM generated':<20s} {data_label_1_proportion:<20.4f} {train_data_label_1_propotion:<20.4f} {pretest_data_label_1_propotion:<20.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the features of the training data: 126635\n",
      "Number of entries in the features of the test data: 31659\n",
      "({'in': True, 'the': True, 'vast': True, 'and': True, 'treacherous': True, 'realm': True, 'of': True, 'underworld': True, ',': True, 'i': True, 'sindra': True, 'reigned': True, 'supreme': True, 'as': True, 'an': True, 'end-game': True, 'level': True, '50': True, 'god': True, '.': True, 'with': True, 'my': True, 'mastery': True, 'over': True, 'dark': True, 'magic': True, 'unparalleled': True, 'strength': True, 'was': True, 'feared': True, 'by': True, 'all': True, 'who': True, 'dared': True, 'to': True, 'challenge': True, 'me': True, 'however': True, 'position': True, 'power': True, 'would': True, 'soon': True, 'be': True, 'put': True, 'test': True, 'most': True, 'unexpected': True, 'manner': True, 'one': True, 'gloomy': True, 'day': True, 'strolled': True, 'through': True, 'desolate': True, 'plains': True, 'a': True, 'peculiar': True, 'sight': True, 'caught': True, 'attention': True, 'young': True, 'player': True, 'adorned': True, 'rags': True, 'brandishing': True, 'wooden': True, 'sword': True, 'relentlessly': True, 'pestering': True, 'repeatedly': True, 'hitting': True, 'ankle': True, 'baffled': True, 'this': True, 'audacious': True, 'display': True, 'but': True, 'decided': True, 'humor': True, 'newcomer': True, 'amused': True, \"'s\": True, 'determination': True, 'halted': True, 'kneeled': True, 'down': True, 'bringing': True, 'myself': True, 'same': True, 'persistent': True, 'soul': True, 'gentle': True, 'smile—a': True, 'rare': True, 'underworld—i': True, 'peered': True, 'into': True, 'eyes': True, 'asked': True, '``': True, 'why': True, 'do': True, 'you': True, 'persist': True, 'attacking': True, 'dear': True, '?': True, \"''\": True, 'seemingly': True, 'unphased': True, 'imposing': True, 'presence': True, 'replied': True, 'seek': True, 'audience': True, 'mighty': True, 'can': True, 'grant': True, 'great': True, 'curiosity': True, 'arose': True, 'within': True, 'realized': True, 'that': True, 'despite': True, 'being': True, '1': True, 'possessed': True, 'kind': True, 'high-level': True, 'players': True, 'lacked': True, 'admiration': True, 'filled': True, 'heart': True, 'snapped': True, 'fingers': True, 'summoning': True, 'ball': True, 'fire': True, 'hand': True, 'courage': True, 'further': True, 'without': True, 'hint': True, 'fear': True, 'stood': True, 'firm': True, 'unwavering': True, 'surprised': True, 'individual': True, 'opportunity': True, 'for': True, 'their': True, 'spirit': True, 'moved': True, 'carefully': True, 'transferred': True, 'fraction': True, 'godlike': True, 'flowed': True, 'weapon': True, 'its': True, 'appearance': True, 'transformed': True, 'glowing': True, 'radiant': True, 'light': True, 'astounded': True, 'reborn': True, 'warrior': True, 'word': True, 'incredible': True, 'event': True, 'spread': True, 'like': True, 'wildfire': True, 'throughout': True, 'attracting': True, 'from': True, 'far': True, 'wide': True, 'many': True, 'sought': True, 'favor': True, 'hoping': True, 'granted': True, 'powers': True, 'beyond': True, 'wildest': True, 'dreams': True, 'once': True, 'bustling': True, 'arena': True, 'competition': True, 'where': True, 'battled': True, 'another': True, 'chance': True, 'divine': True, 'became': True, 'beacon': True, 'hope': True, 'guiding': True, 'those': True, 'willing': True, 'prove': True, 'mettle': True, 'end': True, 'even': True, 'though': True, 'had': True, 'reached': True, 'pinnacle': True, 'true': True, 'reward': True, 'lay': True, 'journey': True, 'rather': True, 'than': True, 'destination': True, 'manifested': True, 'form': True, 'brave': True, 'little': True, 'sheer': True, 'glimmering': True, 'reminded': True, 'thrill': True, 'starting': True, 'small': True, 'defying': True, 'odds': True, 'so': True, 'remained': True, 'also': True, 'humble': True, 'guide': True, 'inspiring': True, 'countless': True, 'others': True, 'rise': True, 'up': True, 'surpass': True, 'limits': True, 'insurmountable': True}, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_features(text):\n",
    "    \"\"\"\n",
    "    A simple feature extractor, based on Kochmar, 2022, p. 171\n",
    "\n",
    "    :param text: a string\n",
    "    :return: a dictionary of features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    words = text.split(' ')\n",
    "    for word in words:\n",
    "        features[word.lower()] = True\n",
    "    return features\n",
    "\n",
    "train_features = [(get_features(row['tokens']), row['label']) for _, row in train_data.iterrows()]\n",
    "pretest_features = [(get_features(row['tokens']), row['label']) for _, row in pretest_data.iterrows()]\n",
    "test_features = [(get_features(row['tokens']), row['label']) for _, row in test_data.iterrows()]\n",
    "\n",
    "print(f\"Number of entries in the features of the training data: {len(train_features)}\")\n",
    "print(f\"Number of entries in the features of the test data: {len(pretest_features)}\")\n",
    "\n",
    "print(train_features[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the training data: 0.7527611518213968\n",
      "F1 score on the pretest data: 0.7429676076234851\n",
      "F1 score on the test data: 0.9588292238483002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels_train = [label for _, label in train_features]\n",
    "labels_pretest = [label for _, label in pretest_features]\n",
    "labels_test = [label for _, label in test_features]\n",
    "predicted_labels_train = [classifier.classify(featureset) for featureset, _ in train_features]\n",
    "predicted_labels_pretest = [classifier.classify(featureset) for featureset, _ in pretest_features]\n",
    "predicted_labels_test = [classifier.classify(featureset) for featureset, _ in test_features]\n",
    "print(f\"F1 score on the training data: {f1_score(labels_train, predicted_labels_train)}\")\n",
    "print(f\"F1 score on the pretest data: {f1_score(labels_pretest, predicted_labels_pretest)}\")\n",
    "print(f\"F1 score on the test data: {f1_score(labels_test, predicted_labels_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
