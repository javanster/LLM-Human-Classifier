{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size before removing rows identical to the training data: 73573\n",
      "Train and pretest data size: 158294\n",
      "Test data size: 40202\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_and_pretest_data = pd.read_csv('data/detect_ai.csv')\n",
    "test_data = pd.read_csv('data/daigt_v4.csv')\n",
    "\n",
    "print(f\"Test data size before removing rows identical to the training data: {len(test_data)}\")\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data.drop_duplicates(subset='text')\n",
    "test_data = test_data[~test_data['text'].isin(train_and_pretest_data['text'])]\n",
    "\n",
    "print(f\"Train and pretest data size: {len(train_and_pretest_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "# nltk.download('punkt') # Uncomment this line if you haven't downloaded the 'punkt' package\n",
    "\n",
    "def preprocess_data(data):\n",
    "    tokens = word_tokenize(data.lower())\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "train_pretest_tokenized_df = pd.DataFrame(columns=['tokens', 'label'])\n",
    "test_tokenized_df = pd.DataFrame(columns=['tokens', 'label'])\n",
    "\n",
    "for index, row in train_and_pretest_data.iterrows():\n",
    "    train_pretest_tokenized_df = pd.concat([train_pretest_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['generated']}, index=[0])], ignore_index=True)\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    test_tokenized_df = pd.concat([test_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['label']}, index=[0])], ignore_index=True)\n",
    "\n",
    "train_data, pretest_data = train_test_split(train_pretest_tokenized_df, stratify=train_pretest_tokenized_df.label, test_size=0.2)\n",
    "\n",
    "train_data.to_csv(\"data/baseline_processed_train_data.csv\")\n",
    "pretest_data.to_csv(\"data/baseline_processed_pretest_data.csv\")\n",
    "test_tokenized_df.to_csv(\"data/baseline_processed_test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the training data: 126635\n",
      "Number of entries in the test data: 31659\n",
      "\n",
      "\n",
      "Proportion of the data:\n",
      "\n",
      "                     Data overall         Train data           Test data           \n",
      "Human written        0.2288               0.2288               0.2288              \n",
      "LLM generated        0.7712               0.7712               0.7712              \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/baseline_processed_train_data.csv\")\n",
    "pretest_data = pd.read_csv(\"data/baseline_processed_pretest_data.csv\")\n",
    "test_data = pd.read_csv(\"data/baseline_processed_test_data.csv\")\n",
    "\n",
    "print(f\"Number of entries in the training data: {train_data.shape[0]}\")\n",
    "print(f\"Number of entries in the test data: {pretest_data.shape[0]}\")\n",
    "\n",
    "data_label_0_proportion = train_and_pretest_data[train_and_pretest_data.generated == 0].shape[0] / train_and_pretest_data.shape[0]\n",
    "data_label_1_proportion = train_and_pretest_data[train_and_pretest_data.generated == 1].shape[0] / train_and_pretest_data.shape[0]\n",
    "\n",
    "train_data_label_0_propotion = train_data[train_data.label == 0].shape[0] / train_data.shape[0]\n",
    "train_data_label_1_propotion = train_data[train_data.label == 1].shape[0] / train_data.shape[0]\n",
    "\n",
    "pretest_data_label_0_propotion = pretest_data[pretest_data.label == 0].shape[0] / pretest_data.shape[0]\n",
    "pretest_data_label_1_propotion = pretest_data[pretest_data.label == 1].shape[0] / pretest_data.shape[0]\n",
    "\n",
    "print(\"\\n\\nProportion of the data:\")\n",
    "print(f\"\\n{'':<20s} {'Data overall':<20s} {'Train data':<20s} {'Test data':<20s}\")\n",
    "print(f\"{'Human written':<20s} {data_label_0_proportion:<20.4f} {train_data_label_0_propotion:<20.4f} {pretest_data_label_0_propotion:<20.4f}\")\n",
    "print(f\"{'LLM generated':<20s} {data_label_1_proportion:<20.4f} {train_data_label_1_propotion:<20.4f} {pretest_data_label_1_propotion:<20.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the features of the training data: 126635\n",
      "Number of entries in the features of the test data: 31659\n",
      "({'have': True, 'you': True, 'heard': True, 'about': True, 'the': True, 'face': True, 'on': True, 'mars': True, '?': True, 'well': True, 'sates': True, 'say': True, 'that': True, 'it': True, 'was': True, 'put': True, 'there': True, 'by': True, 'aliens': True, '.': True, 'but': True, 'for': True, 'now': True, 'im': True, 'going': True, 'to': True, 'tell': True, 'how': True, 'i': True, 'think': True, 'is': True, 'natrual': True, 'in': True, 'my': True, 'opinion': True, 'a': True, 'landform': True, 'not': True, 'one': True, 'if': True, 'couldnt': True, 'been': True, 'some': True, 'type': True, 'of': True, 'markings': True, 'somewhere': True, 'because': True, 'he/she': True, 'can': True, 'leave': True, 'tracks': True, 'too': True, 'fact': True, 'havent': True, 'this': True, 'they': True, 'did': True, 'then': True, 'could': True, 'would': True, 'be': True, 'siad': True, 'its': True, 'just': True, 'mean': True, 'might': True, 'evidence': True, 'also': True, 'mistaken': True, 'natual': True, 'thing': True, 'and': True, 'where': True, 'came': True, 'from': True, 'statements': True, 'dont': True, 'believe': True, 'slightly': True, 'untrue': True, 'them': True, 'had': True, 'gone': True, 'alien': True, 'own': True, 'becuase': True, 'belive': True, 'are': True, 'real': True, 'course': True, 'huverdence': True, 'wernt': True, 'any': True, 'trackings': True, 'seen': True, 'so': True, 'teh': True, 'scientist': True, 'work': True, 'scientists': True, \"n't\": True, 'no': True, 'will': True, 'know': True, 'what': True, 'cant': True, 'look': True, 'up': True, 'little': True, 'thats': True, 'gon': True, 'na': True, 'break': True, 'down': True, 'give': True, 'all': True}, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_features(text):\n",
    "    \"\"\"\n",
    "    A simple feature extractor, based on Kochmar, 2022, p. 171\n",
    "\n",
    "    :param text: a string\n",
    "    :return: a dictionary of features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    words = text.split(' ')\n",
    "    for word in words:\n",
    "        features[word.lower()] = True\n",
    "    return features\n",
    "\n",
    "train_features = [(get_features(row['tokens']), row['label']) for _, row in train_data.iterrows()]\n",
    "pretest_features = [(get_features(row['tokens']), row['label']) for _, row in pretest_data.iterrows()]\n",
    "test_features = [(get_features(row['tokens']), row['label']) for _, row in test_data.iterrows()]\n",
    "\n",
    "print(f\"Number of entries in the features of the training data: {len(train_features)}\")\n",
    "print(f\"Number of entries in the features of the test data: {len(pretest_features)}\")\n",
    "\n",
    "print(train_features[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the training data: 0.751728175171572\n",
      "F1 score on the pretest data: 0.7372742200328407\n",
      "F1 score on the test data: 0.9595777402266988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels_train = [label for _, label in train_features]\n",
    "labels_pretest = [label for _, label in pretest_features]\n",
    "labels_test = [label for _, label in test_features]\n",
    "predicted_labels_train = [classifier.classify(featureset) for featureset, _ in train_features]\n",
    "predicted_labels_pretest = [classifier.classify(featureset) for featureset, _ in pretest_features]\n",
    "predicted_labels_test = [classifier.classify(featureset) for featureset, _ in test_features]\n",
    "print(f\"F1 score on the training data: {f1_score(labels_train, predicted_labels_train)}\")\n",
    "print(f\"F1 score on the pretest data: {f1_score(labels_pretest, predicted_labels_pretest)}\")\n",
    "print(f\"F1 score on the test data: {f1_score(labels_test, predicted_labels_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9w/2pytp4_s6bj5_ff4zz3vl8ph0000gn/T/ipykernel_20567/592256311.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_v2_tokenized_df = pd.concat([test_v2_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['generated']}, index=[0])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test data v2: 0.8559844459993529\n"
     ]
    }
   ],
   "source": [
    "test_v2_data = pd.read_csv('data/ai_vs_human.csv')\n",
    "train_and_pretest_data = pd.read_csv('data/detect_ai.csv')\n",
    "test_data = pd.read_csv('data/daigt_v4.csv')\n",
    "\n",
    "test_v2_data = test_v2_data[~test_v2_data['text'].isin(train_and_pretest_data['text'])]\n",
    "test_v2_data = test_v2_data[~test_v2_data['text'].isin(test_data['text'])]\n",
    "\n",
    "print(len(test_v2_data))\n",
    "\n",
    "test_v2_tokenized_df = pd.DataFrame(columns=['tokens', 'label'])\n",
    "\n",
    "for index, row in test_v2_data.iterrows():\n",
    "    test_v2_tokenized_df = pd.concat([test_v2_tokenized_df, pd.DataFrame({'tokens': preprocess_data(row['text']), 'label': row['generated']}, index=[0])], ignore_index=True)\n",
    "\n",
    "test_v2_features = [(get_features(row['tokens']), row['label']) for _, row in test_v2_tokenized_df.iterrows()]\n",
    "\n",
    "labels_test_v2 = [label for _, label in test_v2_features]\n",
    "predicted_labels_test_v2 = [classifier.classify(featureset) for featureset, _ in test_v2_features]\n",
    "print(f\"F1 score on the test data v2: {f1_score(labels_test_v2, predicted_labels_test_v2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
