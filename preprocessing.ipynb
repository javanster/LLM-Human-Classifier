{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size before removing rows identical to the training data: 73573\n",
      "Train and pretest data size: 158294\n",
      "Validation data size: 1679\n",
      "Test data size: 40202\n",
      "The valdation data is 0.84% of the total data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_and_pretest_data = pd.read_csv('data/detect_ai.csv')\n",
    "valid_data = pd.read_csv('data/detect_ai_validation.csv')\n",
    "test_data = pd.read_csv('data/daigt_v4.csv')\n",
    "\n",
    "print(f\"Test data size before removing rows identical to the training data: {len(test_data)}\")\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data.drop_duplicates(subset='text')\n",
    "test_data = test_data[~test_data['text'].isin(train_and_pretest_data['text'])]\n",
    "\n",
    "print(f\"Train and pretest data size: {len(train_and_pretest_data)}\")\n",
    "print(f\"Validation data size: {len(valid_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "valid_data_percentage = len(valid_data) / (len(train_and_pretest_data) + len(test_data) + len(valid_data))\n",
    "\n",
    "print(f\"The valdation data is {valid_data_percentage * 100:.2f}% of the total data\")\n",
    "\n",
    "# start a timer such that we know how the entire notebook takes to run\n",
    "import time\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and pretest data columns: Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')\n",
      "Validation data columns: Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')\n",
      "Test data columns: Index(['text', 'label', 'prompt_name', 'source', 'RDizzl3_seven', 'model'], dtype='object')\n",
      "Test data[model] has the following values: ['human' 'mistral' 'llama' 'gpt' 'claude' 'falcon' 'palm' 'cohere' 'ada'\n",
      " 'babbage' 'curie' 'davinci']\n"
     ]
    }
   ],
   "source": [
    "# Print the name of the columns in the dfs\n",
    "print(f\"Train and pretest data columns: {train_and_pretest_data.columns}\")\n",
    "print(f\"Validation data columns: {valid_data.columns}\")\n",
    "print(f\"Test data columns: {test_data.columns}\")\n",
    "\n",
    "# print what values test_data[model]] has\n",
    "print(f\"Test data[model] has the following values: {test_data['model'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and pretest data columns: Index(['text', 'generated'], dtype='object')\n",
      "Validation data columns: Index(['text', 'generated'], dtype='object')\n",
      "Test data columns: Index(['text', 'generated'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In recent years, there has been a growing move...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---\\nWhy not cars in our life\\n===============...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A car is considered by many a nessecity for ev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H\\n\\nello fellow citezens , we are here to inf...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you ever known how if feels not being abl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  In recent years, there has been a growing move...       True\n",
       "1  ---\\nWhy not cars in our life\\n===============...       True\n",
       "2  A car is considered by many a nessecity for ev...       True\n",
       "3  H\\n\\nello fellow citezens , we are here to inf...      False\n",
       "4  Have you ever known how if feels not being abl...       True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Irrelevant Data\n",
    "# and renaming the columns to be the same for all datasets\n",
    "# to ['text', 'generated'] as string, boolean\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data[['text', 'generated']]\n",
    "valid_data = valid_data[['text', 'generated']]\n",
    "\n",
    "# Convert 'generated' from 1 or 0 to True or False for both datasets\n",
    "train_and_pretest_data['generated'] = train_and_pretest_data['generated'].astype(bool)\n",
    "valid_data['generated'] = valid_data['generated'].astype(bool)\n",
    "\n",
    "# For the Test dataset\n",
    "test_data['generated'] = test_data['model'] != 'human'\n",
    "test_data = test_data[['text', 'generated']]\n",
    "\n",
    "print(f\"Train and pretest data columns: {train_and_pretest_data.columns}\")\n",
    "print(f\"Validation data columns: {valid_data.columns}\")\n",
    "print(f\"Test data columns: {test_data.columns}\")\n",
    "\n",
    "train_and_pretest_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # download these if it's your first time running the code\\nimport nltk\\nnltk.download('punkt')\\nnltk.download('wordnet')\\nnltk.download('stopwords')\\nnltk.download('averaged_perceptron_tagger')\\nnltk.download('vader_lexicon')\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # download these if it's your first time running the code\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start commenting in train_and_pretest_data & test_data from here and below if you want to process all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#train_and_pretest_data['tokenized_text'] = train_and_pretest_data['text'].apply(word_tokenize)\n",
    "valid_data['tokenized_text'] = valid_data['text'].apply(word_tokenize)\n",
    "#test_data['tokenized_text'] = test_data['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "\n",
    "#train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])\n",
    "#test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(_, NN), (,, ,), (_, FW), (_and, NN), (it, PR...\n",
       "1    [(there, EX), (are, VBP), (advantages, NNS), (...\n",
       "2    [(limiting, VBG), (car, NN), (usage, NN), (ii,...\n",
       "3    [(cars, NNS), (have, VBP), (been, VBN), (one, ...\n",
       "4    [(are, VBP), (cars, NNS), (even, RB), (really,...\n",
       "Name: pos_tags, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax and Grammar Patterns\n",
    "from nltk import pos_tag\n",
    "\n",
    "#train_and_pretest_data['pos_tags'] = train_and_pretest_data['tokenized_text'].apply(pos_tag)\n",
    "valid_data['pos_tags'] = valid_data['tokenized_text'].apply(pos_tag)\n",
    "#test_data['pos_tags'] = test_data['tokenized_text'].apply(pos_tag)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Write code here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "valid_data['pos_tags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>av_sentence_length</th>\n",
       "      <th>vocabulary_diversity</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>zipfian_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.666667</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>57.27</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>68.81</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>83.80</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.939394</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>96.18</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   av_sentence_length  vocabulary_diversity  flesch_reading_ease  \\\n",
       "0           68.666667              0.577670                77.77   \n",
       "1           41.666667              0.432000                57.27   \n",
       "2           21.000000              0.510204                68.81   \n",
       "3           23.000000              0.536232                83.80   \n",
       "4            9.939394              0.027439                96.18   \n",
       "\n",
       "   zipfian_coefficient  \n",
       "0             1.125000  \n",
       "1             1.300000  \n",
       "2             1.142857  \n",
       "3             1.222222  \n",
       "4             1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Complexity and Diversity\n",
    "\"\"\"Features like sentence length,\n",
    "lexical diversity, sentiment analysis,\n",
    "and complexity of ideas could also be\n",
    "indicative of the source of the text.\"\"\"\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Function to calculate average sentence length in words\n",
    "def average_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if sentences:  # Check if there are any sentences to avoid division by zero\n",
    "        return sum(len(word_tokenize(sentence)) for sentence in sentences) / len(sentences)\n",
    "    else:\n",
    "        return 0  # Return 0 if text contains no sentences\n",
    "\n",
    "#train_and_pretest_data['av_sentence_length'] = train_and_pretest_data['text'].apply(average_sentence_length)\n",
    "valid_data['av_sentence_length'] = valid_data['text'].apply(average_sentence_length)\n",
    "#test_data['av_sentence_length'] = test_data['text'].apply(average_sentence_length)\n",
    "\n",
    "# Lexical diversity\n",
    "from nltk import FreqDist\n",
    "\n",
    "#train_and_pretest_data['vocabulary_diversity'] = train_and_pretest_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "valid_data['vocabulary_diversity'] = valid_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "#test_data['vocabulary_diversity'] = test_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "\n",
    "# Readability\n",
    "\"\"\"The Flesch Reading Ease score is a\n",
    "readability test that provides a numerical\n",
    "score indicating how easy or difficult a\n",
    "text is to understand. The score is calculated\n",
    "based on the average length of sentences and\n",
    "the average number of syllables per word in the text.\n",
    "Scores typically range from 0 to 100,\n",
    "with higher scores indicating easier readability.\n",
    "Here's what the scores generally imply:\n",
    "\n",
    "90-100: Very easy to read, easily understood by an average 11-year-old student.\n",
    "60-70: Plain English, easily understood by 13- to 15-year-old students.\n",
    "0-30: Very difficult to read, best understood by university graduates.\n",
    "This metric is commonly used in educational settings and for assessing the accessibility of texts to different audiences.\"\"\"\n",
    "from textstat import flesch_reading_ease\n",
    "\n",
    "#train_and_pretest_data['flesch_reading_ease'] = train_and_pretest_data['text'].apply(flesch_reading_ease)\n",
    "valid_data['flesch_reading_ease'] = valid_data['text'].apply(flesch_reading_ease)\n",
    "#test_data['flesch_reading_ease'] = test_data['text'].apply(flesch_reading_ease)\n",
    "\n",
    "\n",
    "\n",
    "# Zipfian Coefficient\n",
    "\"\"\"The Zipfian coefficient is a measure of the\n",
    "distribution of word frequencies in a text.\n",
    "It is calculated by plotting the frequency of\n",
    "each word in the text against its rank in the\n",
    "frequency table and fitting a curve to the data.\n",
    "\"\"\"\n",
    "from nltk import ngrams\n",
    "\n",
    "def zipfian_coefficient(text, n=1):\n",
    "    ngrams_list = list(ngrams(text, n))\n",
    "    freq_dist = FreqDist(ngrams_list)\n",
    "    freq_values = list(freq_dist.values())\n",
    "    freq_values.sort(reverse=True)\n",
    "    return freq_values[0] / freq_values[1]\n",
    "\n",
    "#train_and_pretest_data['zipfian_coefficient'] = train_and_pretest_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "valid_data['zipfian_coefficient'] = valid_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "#test_data['zipfian_coefficient'] = test_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "\n",
    "# Perplexity\n",
    "# Denne er fra artikeln men jeg fikk den ikke til å fungere\n",
    "\"\"\" \"Perplexity serves as another widely used metric for LLM-\n",
    "generated text detection. It measures the degree of uncer-\n",
    "tainty or surprise in predicting the next word in a sequence,\n",
    "\n",
    "based on the preceding words, by calculating the negative\n",
    "average log-likelihood of the texts under the language model\n",
    "[5].\" \"\"\"\n",
    "\"\"\"\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "def perplexity(text, n=2):\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n, text)\n",
    "    model = MLE(n)\n",
    "    model.fit(train_data, padded_sents)\n",
    "    return model.perplexity(text)\n",
    "\n",
    "#train_and_pretest_data['perplexity'] = train_and_pretest_data['tokenized_text'].apply(perplexity)\n",
    "valid_data['perplexity'] = valid_data['tokenized_text'].apply(perplexity)\n",
    "#test_data['perplexity'] = test_data['tokenized_text'].apply(perplexity)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# print the head of the new features for valid_data\n",
    "valid_data[['av_sentence_length', 'vocabulary_diversity', 'flesch_reading_ease', 'zipfian_coefficient']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data['tokenized_text'] after removing stopwords: 0    [_, ,, _, _and, fact, automobile, ,, danger, g...\n",
      "1    [advantages, limiting, car, usage, less, green...\n",
      "2    [limiting, car, usage, ii, beneifial, envirome...\n",
      "3    [cars, one, advanced, invention, world, ;, las...\n",
      "4    [cars, even, really, necessary, ?, vehicles, c...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stop word removal\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Removing stopwords from the text\n",
    "#train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "#test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "print(f\"valid_data['tokenized_text'] after removing stopwords: {valid_data['tokenized_text'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data['tokenized_text'] after lemmatization: 0    [_, ,, _, _and, fact, automobile, ,, danger, g...\n",
      "1    [advantage, limiting, car, usage, le, greenhou...\n",
      "2    [limiting, car, usage, ii, beneifial, envirome...\n",
      "3    [car, one, advanced, invention, world, ;, last...\n",
      "4    [car, even, really, necessary, ?, vehicle, cau...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize the text\n",
    "#train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "#test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "print(f\"valid_data['tokenized_text'] after lemmatization: {valid_data['tokenized_text'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.5878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.069  0.878  0.053    0.1397\n",
       "1  0.069  0.832  0.099    0.8277\n",
       "2  0.044  0.868  0.087    0.9392\n",
       "3  0.088  0.802  0.110    0.5878\n",
       "4  0.311  0.689  0.000   -0.9996"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#train_and_pretest_data['sentiment_scores'] = train_and_pretest_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "#sentiment_columns = train_and_pretest_data['sentiment_scores'].apply(pd.Series)\n",
    "#train_and_pretest_data = pd.concat([train_and_pretest_data, sentiment_columns], axis=1)\n",
    "#train_and_pretest_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "valid_data['sentiment_scores'] = valid_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "sentiment_columns = valid_data['sentiment_scores'].apply(pd.Series)\n",
    "valid_data = pd.concat([valid_data, sentiment_columns], axis=1)\n",
    "valid_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "#test_data['sentiment_scores'] = test_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "#sentiment_columns = test_data['sentiment_scores'].apply(pd.Series)\n",
    "#test_data = pd.concat([test_data, sentiment_columns], axis=1)\n",
    "#test_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "valid_data[['neg', 'neu', 'pos', 'compound']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'text' and 'tokenized_text' columns from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all features to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the notebook: 81.41 seconds\n",
      "\n",
      "Time it will take to run the entire notebook for all the data:\n",
      "2 hours, 41 minutes, and 46.19 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# stop and print timer such that we know how the entire notebook takes to run\n",
    "end = time.time()\n",
    "print(f\"Time taken to run the notebook: {end - start:.2f} seconds\")\n",
    "\n",
    "total_seconds = (end - start) / valid_data_percentage\n",
    "hours = int(total_seconds // 3600)\n",
    "minutes = int((total_seconds % 3600) // 60)\n",
    "seconds = total_seconds % 60\n",
    "\n",
    "print(f\"\\nTime it will take to run the entire notebook for all the data:\\n{hours} hours, {minutes} minutes, and {seconds:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
