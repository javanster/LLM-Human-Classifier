{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size before removing rows identical to the training data: 73573\n",
      "Train and pretest data size: 158294\n",
      "Validation data size: 1679\n",
      "Test data size: 40202\n",
      "The valdation data is 0.84% of the total data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_and_pretest_data = pd.read_csv('data/detect_ai.csv')\n",
    "valid_data = pd.read_csv('data/detect_ai_validation.csv')\n",
    "test_data = pd.read_csv('data/daigt_v4.csv')\n",
    "\n",
    "print(f\"Test data size before removing rows identical to the training data: {len(test_data)}\")\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data.drop_duplicates(subset='text')\n",
    "test_data = test_data[~test_data['text'].isin(train_and_pretest_data['text'])]\n",
    "\n",
    "print(f\"Train and pretest data size: {len(train_and_pretest_data)}\")\n",
    "print(f\"Validation data size: {len(valid_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "valid_data_percentage = len(valid_data) / (len(train_and_pretest_data) + len(test_data) + len(valid_data))\n",
    "\n",
    "print(f\"The valdation data is {valid_data_percentage * 100:.2f}% of the total data\")\n",
    "\n",
    "# start a timer such that we know how the entire notebook takes to run\n",
    "import time\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this variable to True if you want to process all 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAll = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and pretest data columns: Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')\n",
      "Validation data columns: Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')\n",
      "Test data columns: Index(['text', 'label', 'prompt_name', 'source', 'RDizzl3_seven', 'model'], dtype='object')\n",
      "Test data[model] has the following values: ['human' 'mistral' 'llama' 'gpt' 'claude' 'falcon' 'palm' 'cohere' 'ada'\n",
      " 'babbage' 'curie' 'davinci']\n"
     ]
    }
   ],
   "source": [
    "# Print the name of the columns in the dfs\n",
    "print(f\"Train and pretest data columns: {train_and_pretest_data.columns}\")\n",
    "print(f\"Validation data columns: {valid_data.columns}\")\n",
    "print(f\"Test data columns: {test_data.columns}\")\n",
    "\n",
    "# print what values test_data[model]] has\n",
    "print(f\"Test data[model] has the following values: {test_data['model'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and pretest data columns: Index(['text', 'generated'], dtype='object')\n",
      "Validation data columns: Index(['text', 'generated'], dtype='object')\n",
      "Test data columns: Index(['text', 'generated'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In recent years, there has been a growing move...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---\\nWhy not cars in our life\\n===============...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A car is considered by many a nessecity for ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H\\n\\nello fellow citezens , we are here to inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you ever known how if feels not being abl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  In recent years, there has been a growing move...          1\n",
       "1  ---\\nWhy not cars in our life\\n===============...          1\n",
       "2  A car is considered by many a nessecity for ev...          1\n",
       "3  H\\n\\nello fellow citezens , we are here to inf...          0\n",
       "4  Have you ever known how if feels not being abl...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Irrelevant Data\n",
    "# and renaming the columns to be the same for all datasets\n",
    "# to ['text', 'generated'] as string, boolean\n",
    "\n",
    "train_and_pretest_data = train_and_pretest_data[['text', 'generated']]\n",
    "valid_data = valid_data[['text', 'generated']]\n",
    "\n",
    "\n",
    "# For the Test dataset\n",
    "test_data['generated'] = (test_data['model'] != 'human').astype(int)\n",
    "test_data = test_data[['text', 'generated']]\n",
    "\n",
    "print(f\"Train and pretest data columns: {train_and_pretest_data.columns}\")\n",
    "print(f\"Validation data columns: {valid_data.columns}\")\n",
    "print(f\"Test data columns: {test_data.columns}\")\n",
    "\n",
    "train_and_pretest_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # download these if it's your first time running the code\\nimport nltk\\nnltk.download('punkt')\\nnltk.download('wordnet')\\nnltk.download('stopwords')\\nnltk.download('averaged_perceptron_tagger')\\nnltk.download('vader_lexicon')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # download these if it's your first time running the code\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start commenting in train_and_pretest_data & test_data from here and below if you want to process all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk import word_tokenize\n",
    "\n",
    "valid_data['tokenized_text'] = valid_data['text'].apply(word_tokenize)\n",
    "if runAll:\n",
    "    train_and_pretest_data['tokenized_text'] = train_and_pretest_data['text'].apply(word_tokenize)\n",
    "    test_data['tokenized_text'] = test_data['text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])\n",
    "if runAll:\n",
    "    train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])\n",
    "    test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(_, NN), (,, ,), (_, FW), (_and, NN), (it, PR...\n",
       "1    [(there, EX), (are, VBP), (advantages, NNS), (...\n",
       "2    [(limiting, VBG), (car, NN), (usage, NN), (ii,...\n",
       "3    [(cars, NNS), (have, VBP), (been, VBN), (one, ...\n",
       "4    [(are, VBP), (cars, NNS), (even, RB), (really,...\n",
       "Name: pos_tags, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax and Grammar Patterns\n",
    "from nltk import pos_tag\n",
    "\n",
    "valid_data['pos_tags'] = valid_data['tokenized_text'].apply(pos_tag)\n",
    "\n",
    "if runAll:\n",
    "    train_and_pretest_data['pos_tags'] = train_and_pretest_data['tokenized_text'].apply(pos_tag)\n",
    "    test_data['pos_tags'] = test_data['tokenized_text'].apply(pos_tag)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Write code here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "valid_data['pos_tags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>av_sentence_length</th>\n",
       "      <th>vocabulary_diversity</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>zipfian_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.666667</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>57.27</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>68.81</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>83.80</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.939394</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>96.18</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   av_sentence_length  vocabulary_diversity  flesch_reading_ease  \\\n",
       "0           68.666667              0.577670                77.77   \n",
       "1           41.666667              0.432000                57.27   \n",
       "2           21.000000              0.510204                68.81   \n",
       "3           23.000000              0.536232                83.80   \n",
       "4            9.939394              0.027439                96.18   \n",
       "\n",
       "   zipfian_coefficient  \n",
       "0             1.125000  \n",
       "1             1.300000  \n",
       "2             1.142857  \n",
       "3             1.222222  \n",
       "4             1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Complexity and Diversity\n",
    "\"\"\"Features like sentence length,\n",
    "lexical diversity, sentiment analysis,\n",
    "and complexity of ideas could also be\n",
    "indicative of the source of the text.\"\"\"\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Function to calculate average sentence length in words\n",
    "def average_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if sentences:  # Check if there are any sentences to avoid division by zero\n",
    "        return sum(len(word_tokenize(sentence)) for sentence in sentences) / len(sentences)\n",
    "    else:\n",
    "        return 0  # Return 0 if text contains no sentences\n",
    "\n",
    "valid_data['av_sentence_length'] = valid_data['text'].apply(average_sentence_length)\n",
    "\n",
    "if runAll:\n",
    "    train_and_pretest_data['av_sentence_length'] = train_and_pretest_data['text'].apply(average_sentence_length)\n",
    "    test_data['av_sentence_length'] = test_data['text'].apply(average_sentence_length)\n",
    "    \n",
    "# Lexical diversity\n",
    "from nltk import FreqDist\n",
    "\n",
    "valid_data['vocabulary_diversity'] = valid_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "if runAll:\n",
    "    train_and_pretest_data['vocabulary_diversity'] = train_and_pretest_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "    test_data['vocabulary_diversity'] = test_data['tokenized_text'].apply(lambda x: len(set(x)) / len(x))\n",
    "\n",
    "# Readability\n",
    "\"\"\"The Flesch Reading Ease score is a\n",
    "readability test that provides a numerical\n",
    "score indicating how easy or difficult a\n",
    "text is to understand. The score is calculated\n",
    "based on the average length of sentences and\n",
    "the average number of syllables per word in the text.\n",
    "Scores typically range from 0 to 100,\n",
    "with higher scores indicating easier readability.\n",
    "Here's what the scores generally imply:\n",
    "\n",
    "90-100: Very easy to read, easily understood by an average 11-year-old student.\n",
    "60-70: Plain English, easily understood by 13- to 15-year-old students.\n",
    "0-30: Very difficult to read, best understood by university graduates.\n",
    "This metric is commonly used in educational settings and for assessing the accessibility of texts to different audiences.\"\"\"\n",
    "from textstat import flesch_reading_ease\n",
    "\n",
    "valid_data['flesch_reading_ease'] = valid_data['text'].apply(flesch_reading_ease)\n",
    "if runAll:\n",
    "    train_and_pretest_data['flesch_reading_ease'] = train_and_pretest_data['text'].apply(flesch_reading_ease)\n",
    "    test_data['flesch_reading_ease'] = test_data['text'].apply(flesch_reading_ease)\n",
    "\n",
    "\n",
    "\n",
    "# Zipfian Coefficient\n",
    "\"\"\"The Zipfian coefficient is a measure of the\n",
    "distribution of word frequencies in a text.\n",
    "It is calculated by plotting the frequency of\n",
    "each word in the text against its rank in the\n",
    "frequency table and fitting a curve to the data.\n",
    "\"\"\"\n",
    "from nltk import ngrams\n",
    "\n",
    "def zipfian_coefficient(text, n=1):\n",
    "    ngrams_list = list(ngrams(text, n))\n",
    "    freq_dist = FreqDist(ngrams_list)\n",
    "    freq_values = list(freq_dist.values())\n",
    "    freq_values.sort(reverse=True)\n",
    "    return freq_values[0] / freq_values[1]\n",
    "\n",
    "valid_data['zipfian_coefficient'] = valid_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "if runAll:\n",
    "    train_and_pretest_data['zipfian_coefficient'] = train_and_pretest_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "    test_data['zipfian_coefficient'] = test_data['tokenized_text'].apply(zipfian_coefficient)\n",
    "\n",
    "# Perplexity\n",
    "# Denne er fra artikeln men jeg fikk den ikke til å fungere\n",
    "\"\"\" \"Perplexity serves as another widely used metric for LLM-\n",
    "generated text detection. It measures the degree of uncer-\n",
    "tainty or surprise in predicting the next word in a sequence,\n",
    "\n",
    "based on the preceding words, by calculating the negative\n",
    "average log-likelihood of the texts under the language model\n",
    "[5].\" \"\"\"\n",
    "\"\"\"\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "def perplexity(text, n=2):\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n, text)\n",
    "    model = MLE(n)\n",
    "    model.fit(train_data, padded_sents)\n",
    "    return model.perplexity(text)\n",
    "\n",
    "#train_and_pretest_data['perplexity'] = train_and_pretest_data['tokenized_text'].apply(perplexity)\n",
    "valid_data['perplexity'] = valid_data['tokenized_text'].apply(perplexity)\n",
    "#test_data['perplexity'] = test_data['tokenized_text'].apply(perplexity)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# print the head of the new features for valid_data\n",
    "valid_data[['av_sentence_length', 'vocabulary_diversity', 'flesch_reading_ease', 'zipfian_coefficient']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data['tokenized_text'] after removing stopwords: 0    [_, ,, _, _and, fact, automobile, ,, danger, g...\n",
      "1    [advantages, limiting, car, usage, less, green...\n",
      "2    [limiting, car, usage, ii, beneifial, envirome...\n",
      "3    [cars, one, advanced, invention, world, ;, las...\n",
      "4    [cars, even, really, necessary, ?, vehicles, c...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stop word removal\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Removing stopwords from the text\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "if runAll:\n",
    "    train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "    test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "print(f\"valid_data['tokenized_text'] after removing stopwords: {valid_data['tokenized_text'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data['tokenized_text'] after lemmatization: 0    [_, ,, _, _and, fact, automobile, ,, danger, g...\n",
      "1    [advantage, limiting, car, usage, le, greenhou...\n",
      "2    [limiting, car, usage, ii, beneifial, envirome...\n",
      "3    [car, one, advanced, invention, world, ;, last...\n",
      "4    [car, even, really, necessary, ?, vehicle, cau...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize the text\n",
    "valid_data['tokenized_text'] = valid_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "if runAll:\n",
    "    train_and_pretest_data['tokenized_text'] = train_and_pretest_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    test_data['tokenized_text'] = test_data['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "print(f\"valid_data['tokenized_text'] after lemmatization: {valid_data['tokenized_text'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.5878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.069  0.878  0.053    0.1397\n",
       "1  0.069  0.832  0.099    0.8277\n",
       "2  0.044  0.868  0.087    0.9392\n",
       "3  0.088  0.802  0.110    0.5878\n",
       "4  0.311  0.689  0.000   -0.9996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "valid_data['sentiment_scores'] = valid_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "sentiment_columns = valid_data['sentiment_scores'].apply(pd.Series)\n",
    "valid_data = pd.concat([valid_data, sentiment_columns], axis=1)\n",
    "valid_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "if runAll:\n",
    "    train_and_pretest_data['sentiment_scores'] = train_and_pretest_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "    sentiment_columns = train_and_pretest_data['sentiment_scores'].apply(pd.Series)\n",
    "    train_and_pretest_data = pd.concat([train_and_pretest_data, sentiment_columns], axis=1)\n",
    "    train_and_pretest_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "    test_data['sentiment_scores'] = test_data['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "    sentiment_columns = test_data['sentiment_scores'].apply(pd.Series)\n",
    "    test_data = pd.concat([test_data, sentiment_columns], axis=1)\n",
    "    test_data.drop('sentiment_scores', axis=1, inplace=True)\n",
    "\n",
    "valid_data[['neg', 'neu', 'pos', 'compound']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>av_sentence_length</th>\n",
       "      <th>vocabulary_diversity</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>zipfian_coefficient</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_,_ _and it has to do with the fact that if yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[_, ,, _, _and, fact, automobile, ,, danger, g...</td>\n",
       "      <td>[(_, NN), (,, ,), (_, FW), (_and, NN), (it, PR...</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are advantages of limiting car usage les...</td>\n",
       "      <td>1</td>\n",
       "      <td>[advantage, limiting, car, usage, le, greenhou...</td>\n",
       "      <td>[(there, EX), (are, VBP), (advantages, NNS), (...</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>57.27</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limiting car usage ii very beneifial to not on...</td>\n",
       "      <td>1</td>\n",
       "      <td>[limiting, car, usage, ii, beneifial, envirome...</td>\n",
       "      <td>[(limiting, VBG), (car, NN), (usage, NN), (ii,...</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>68.81</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cars have been one of the most advanced invent...</td>\n",
       "      <td>1</td>\n",
       "      <td>[car, one, advanced, invention, world, ;, last...</td>\n",
       "      <td>[(cars, NNS), (have, VBP), (been, VBN), (one, ...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>83.80</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.5878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are cars even really necessary? Vehicles can c...</td>\n",
       "      <td>1</td>\n",
       "      <td>[car, even, really, necessary, ?, vehicle, cau...</td>\n",
       "      <td>[(are, VBP), (cars, NNS), (even, RB), (really,...</td>\n",
       "      <td>9.939394</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>96.18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated  \\\n",
       "0  _,_ _and it has to do with the fact that if yo...          1   \n",
       "1  There are advantages of limiting car usage les...          1   \n",
       "2  Limiting car usage ii very beneifial to not on...          1   \n",
       "3  Cars have been one of the most advanced invent...          1   \n",
       "4  Are cars even really necessary? Vehicles can c...          1   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [_, ,, _, _and, fact, automobile, ,, danger, g...   \n",
       "1  [advantage, limiting, car, usage, le, greenhou...   \n",
       "2  [limiting, car, usage, ii, beneifial, envirome...   \n",
       "3  [car, one, advanced, invention, world, ;, last...   \n",
       "4  [car, even, really, necessary, ?, vehicle, cau...   \n",
       "\n",
       "                                            pos_tags  av_sentence_length  \\\n",
       "0  [(_, NN), (,, ,), (_, FW), (_and, NN), (it, PR...           68.666667   \n",
       "1  [(there, EX), (are, VBP), (advantages, NNS), (...           41.666667   \n",
       "2  [(limiting, VBG), (car, NN), (usage, NN), (ii,...           21.000000   \n",
       "3  [(cars, NNS), (have, VBP), (been, VBN), (one, ...           23.000000   \n",
       "4  [(are, VBP), (cars, NNS), (even, RB), (really,...            9.939394   \n",
       "\n",
       "   vocabulary_diversity  flesch_reading_ease  zipfian_coefficient    neg  \\\n",
       "0              0.577670                77.77             1.125000  0.069   \n",
       "1              0.432000                57.27             1.300000  0.069   \n",
       "2              0.510204                68.81             1.142857  0.044   \n",
       "3              0.536232                83.80             1.222222  0.088   \n",
       "4              0.027439                96.18             1.000000  0.311   \n",
       "\n",
       "     neu    pos  compound  \n",
       "0  0.878  0.053    0.1397  \n",
       "1  0.832  0.099    0.8277  \n",
       "2  0.868  0.087    0.9392  \n",
       "3  0.802  0.110    0.5878  \n",
       "4  0.689  0.000   -0.9996  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 17460)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "valid_data['text_for_tfidf'] = valid_data['tokenized_text'].apply(lambda x: ' '.join(x))\n",
    "valid_data_sparse = TfidfVectorizer().fit_transform(valid_data['text_for_tfidf'])\n",
    "\n",
    "valid_data_sparse.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix.to_csv('tfidf_matrix.csv', index=False)\n",
    "# This matrix was 115 MB, saving sparse matrices as csv will be unfeasable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "valid_data_y = valid_data['generated']\n",
    "valid_data.drop(columns=['generated', 'text', 'tokenized_text', 'pos_tags', 'text_for_tfidf'], inplace=True)\n",
    "\n",
    "# Save the sparse matrix and DataFrames\n",
    "save_npz('valid_data_x_sparse.npz', valid_data_sparse)\n",
    "valid_data.to_csv('valid_data_x_dense.csv', index=False)\n",
    "valid_data_y.to_csv('valid_data_y.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'text' and 'tokenized_text' columns from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all features to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the notebook: 87.29 seconds\n",
      "\n",
      "Time it will take to run the entire notebook for all the data:\n",
      "2 hours, 53 minutes, and 26.98 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# stop and print timer such that we know how the entire notebook takes to run\n",
    "end = time.time()\n",
    "print(f\"Time taken to run the notebook: {end - start:.2f} seconds\")\n",
    "\n",
    "total_seconds = (end - start) / valid_data_percentage\n",
    "hours = int(total_seconds // 3600)\n",
    "minutes = int((total_seconds % 3600) // 60)\n",
    "seconds = total_seconds % 60\n",
    "\n",
    "print(f\"\\nTime it will take to run the entire notebook for all the data:\\n{hours} hours, {minutes} minutes, and {seconds:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to concatinate data from saved .npz and .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1679, 17468)\n",
      "(1679, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use this window\n",
    "# to load datasets and make ready for ML\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "valid_data_x_sparse = load_npz('valid_data_x_sparse.npz')\n",
    "valid_data_x_dense = pd.read_csv('valid_data_x_dense.csv')\n",
    "\n",
    "# Combine the loaded sparse matrix with the additional features\n",
    "valid_data_x = hstack([valid_data_sparse, csr_matrix(valid_data_x_dense.values)]).toarray()\n",
    "valid_data_y = pd.read_csv('valid_data_y.csv')\n",
    "\n",
    "print(valid_data_x.shape)\n",
    "print(valid_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of how to use ML algorithm for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7678571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        78\n",
      "           1       0.77      1.00      0.87       258\n",
      "\n",
      "    accuracy                           0.77       336\n",
      "   macro avg       0.38      0.50      0.43       336\n",
      "weighted avg       0.59      0.77      0.67       336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz, csr_matrix, hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split data (this will be done differently\n",
    "# when dealing with all 3 datasets, not just valid_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    valid_data_x, valid_data_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
